#!/usr/bin/env python3
# recorder.py - PiStreamer with OpenCV + PyAudio + MoviePy (no direct FFmpeg subprocess, merge AVI + WAV to MP4)
import os
import time
import signal
from datetime import datetime
import threading
from pathlib import Path
import sys
import tempfile
import wave  # Built-in for WAV audio
import pyaudio  # For audio capture
from moviepy.video.io.ffmpeg_tools import ffmpeg_merge_video_audio
import requests
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
import cv2

class SegmentManager:
    """Class quáº£n lÃ½ segment cho video vÃ  audio recording"""
    def __init__(self, output_dir, segment_seconds):
        self.output_dir = output_dir
        self.segment_seconds = segment_seconds
        self.current_segment = None
        self.segment_start = 0  # Khá»Ÿi táº¡o vá»›i 0 thay vÃ¬ None
        self._lock = threading.Lock()
        self._segment_complete = {'video': False, 'audio': False}
        self._merge_event = threading.Event()
        
    def start_new_segment(self):
        """Báº¯t Ä‘áº§u segment má»›i vÃ  tráº£ vá» thÃ´ng tin segment"""
        with self._lock:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            self.current_segment = f"{self.output_dir}/{timestamp}_cam0"
            self.segment_start = time.time()
            self._segment_complete = {'video': False, 'audio': False}
            self._merge_event.clear()
            return self.current_segment
            
    def mark_complete(self, stream_type):
        """ÄÃ¡nh dáº¥u má»™t luá»“ng (video/audio) Ä‘Ã£ hoÃ n thÃ nh segment"""
        with self._lock:
            self._segment_complete[stream_type] = True
            if all(self._segment_complete.values()):
                self._merge_event.set()
                
    def wait_for_merge(self, timeout=None):
        """Äá»£i cáº£ video vÃ  audio hoÃ n thÃ nh Ä‘á»ƒ ghÃ©p file"""
        return self._merge_event.wait(timeout)
        
    def should_start_new(self):
        """Kiá»ƒm tra xem Ä‘Ã£ Ä‘áº¿n lÃºc báº¯t Ä‘áº§u segment má»›i chÆ°a"""
        return time.time() - self.segment_start >= self.segment_seconds
        
    def get_current_paths(self):
        """Láº¥y Ä‘Æ°á»ng dáº«n file cho segment hiá»‡n táº¡i"""
        return {
            'video': f"{self.current_segment}.avi",
            'audio': f"{self.current_segment}.wav",
            'output': f"{self.current_segment}.mp4"
        }
from flask import Flask, Response, current_app
from flask_socketio import SocketIO, emit  # For WebSocket stream
from moviepy import VideoFileClip, AudioFileClip  # For merging video + audio to MP4 (pip install moviepy)
import base64  # For encoding frame to base64
from firmware.hal.usb_manager import USBManager    
from firmware.hal.gpio_leds import gpioLed
from firmware.hal.gnss import GNSSModule
from firmware.hal.rtc import rtcModule
from firmware.hal.micro import Micro
from firmware.config.config_loader import load
def _get_pyaudio_device_index(device_name_or_index):
    """
    Convert device name (hw:1,0) hoáº·c string index thÃ nh PyAudio device index.
    
    Args:
        device_name_or_index: cÃ³ thá»ƒ lÃ :
            - int: 0, 1, 2... (PyAudio index)
            - str: "hw:1,0" (ALSA name)
            - str: "1" (string number)
    
    Returns:
        int: PyAudio device index, hoáº·c None náº¿u khÃ´ng tÃ¬m Ä‘Æ°á»£c
    """
    import pyaudio
    
    # Náº¿u Ä‘Ã£ lÃ  int, tráº£ vá» ngay
    if isinstance(device_name_or_index, int):
        return device_name_or_index
    
    # Náº¿u lÃ  string number, convert sang int
    if isinstance(device_name_or_index, str):
        try:
            return int(device_name_or_index)
        except ValueError:
            pass  # KhÃ´ng pháº£i number, tiáº¿p tá»¥c search
    
    # Search device theo tÃªn (ALSA name nhÆ° "hw:1,0")
    p = pyaudio.PyAudio()
    device_str = str(device_name_or_index).lower()
    
    try:
        for i in range(p.get_device_count()):
            info = p.get_device_info_by_index(i)
            device_name = info.get('name', '').lower()
            
            # Check náº¿u tÃªn device match
            if device_str in device_name:
                print(f"   âœ… TÃ¬m tháº¥y device '{device_name}' táº¡i index {i}")
                p.terminate()
                return i
    finally:
        p.terminate()
    
    print(f"   âš ï¸ KhÃ´ng tÃ¬m tháº¥y device '{device_name_or_index}'")
    return None
class PiStreamer:
    def __init__(self,
                 video_dev=0,  # Index for OpenCV
                 audio_dev="hw:1,0",
                 output_dir="/media/ssd",
                 hls_dir="/tmp/picam_hls",  # Not used
                 segment_seconds=30,  # Short for test
                 led_pin=26):
        self.video_dev = video_dev
        self.audio_dev = audio_dev
        self.output_dir = output_dir
        self.hls_dir = hls_dir
        self.segment_seconds = segment_seconds
        self.config_file = Path(__file__).parent.parent / 'config' / 'device_full.yaml'
        self.config = load(self.config_file)
        self.led_control = gpioLed(self.config['gpio'].get('record_led', 26))
        self.led_thread = None
        self.led_running = False
        
        # Init RTC and GNSS
        try:
            self.rtc = rtcModule()
            self.rtc_available = True
            print("âœ… RTC module khá»Ÿi táº¡o thÃ nh cÃ´ng")
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ khá»Ÿi táº¡o RTC: {e}")
            self.rtc_available = False

        try:
            if self.config['capabilities'].get('gnss', False):
                self.gnss = GNSSModule()
                self.gnss_available = True
                print("âœ… GNSS module khá»Ÿi táº¡o thÃ nh cÃ´ng")
            else:
                print("â„¹ï¸ GNSS khÃ´ng Ä‘Æ°á»£c báº­t trong cáº¥u hÃ¬nh")
                self.gnss_available = False
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ khá»Ÿi táº¡o GNSS: {e}")
            self.gnss_available = False

        self._stop_flag = False
        self.cap = None
        self.video_writer = None
        self.audio_writer = None
        self.current_segment = None
        self.segment_start = None
        self.audio_frames = []  # Buffer for audio frames
        self.audio_device_index = None
        self.micro = None

        # Flask app with SocketIO for WebSocket stream
        self.app = Flask(__name__)
        self.app.debug = False  # Disable debug mode to prevent auto-reload
        self.socketio = SocketIO(self.app, cors_allowed_origins="*", async_mode='threading')
        self.frame_queue = []  # Simple queue for frames (latest only to reduce lag)
        self.frame_lock = threading.Lock()
        self.ws_clients = set()  # Track connected WebSocket clients

    def check_liscam(self):
        """TÃ¬m index camera hoáº¡t Ä‘á»™ng - Ä‘Æ¡n giáº£n nhÆ° Flask example"""
        for cam in range(10):  # Thá»­ lÃªn Ä‘áº¿n /dev/video9
            cap = cv2.VideoCapture(cam)
            if cap.isOpened():
                cap.release()
                print(f"âœ… TÃ¬m tháº¥y camera táº¡i index {cam}")
                return cam
        print("âŒ KhÃ´ng tÃ¬m tháº¥y camera nÃ o hoáº¡t Ä‘á»™ng!")
        return 0  # Fallback

    def initial(self):
        """Khá»Ÿi táº¡o cÃ¡c thÃ´ng sá»‘ tá»« file cáº¥u hÃ¬nh"""
        try:
            # Khá»Ÿi táº¡o USB Storage Manager
            self.usb_manager = USBManager(
                path=self.config['paths']['record_root'],
                min_free_gb=self.config['storage'].get('min_free_gb', 1.0),
                min_free_percent=self.config['storage'].get('min_free_percent', 10),
                camera_id=self.config['device'].get('id', 'PICAM-DEFAULT')
            )
            
            # Kiá»ƒm tra vÃ  Ä‘á»£i USB storage
            if not self.usb_manager.is_available():
                print("âš ï¸ Äang Ä‘á»£i USB storage...")
                # Báº¯t Ä‘áº§u nháº¥p nhÃ¡y LED khi khÃ´ng cÃ³ USB
                self._start_led_blink()
                self.usb_manager.wait_until_available()
                # Dá»«ng nháº¥p nhÃ¡y khi Ä‘Ã£ cÃ³ USB
                self._stop_led_blink()
            
            # Kiá»ƒm tra dung lÆ°á»£ng trá»‘ng
            if not self.usb_manager.has_enough_space():
                print("âš ï¸ Dung lÆ°á»£ng trá»‘ng khÃ´ng Ä‘á»§, Ä‘ang dá»n dáº¹p...")
                self.usb_manager.cleanup_old_files()
                if not self.usb_manager.has_enough_space():
                    raise Exception("KhÃ´ng Ä‘á»§ dung lÆ°á»£ng trá»‘ng sau khi dá»n dáº¹p")
            
            print("âœ… USB Storage sáºµn sÃ ng")
            
            # Cáº¥u hÃ¬nh video - sá»­ dá»¥ng index thay vÃ¬ path
            self.video_index = self.check_liscam()  # LÆ°u index int
            self.video_size = self.config['video']['v4l2_format']  # e.g., '640x480'
            self.video_fps = self.config['video']['v4l2_fps']
            width, height = map(int, self.video_size.split('x'))
            self.video_width = width
            self.video_height = height

            # Cáº¥u hÃ¬nh audio náº¿u Ä‘Æ°á»£c báº­t
            if self.config['capabilities'].get('audio', False):
                self.micro = Micro()
                device_str = self.micro.get_first_available_device()
                
                if device_str:
                    # Parse device string
                    # CÃ³ thá»ƒ lÃ : "hw:1,0" hoáº·c "[1] HD camera: USB Audio (hw:1,0)"
                    self.audio_device_index = None
                    
                    # Case 1: Format "[index] name (hw:x,y)"
                    if device_str.startswith('['):
                        try:
                            parts = device_str.split(']')[0].split('[')
                            if len(parts) > 1:
                                self.audio_device_index = int(parts[1].strip())
                        except:
                            pass
                    
                    # Case 2: Just "hw:x,y" - need to find index by querying PyAudio
                    if self.audio_device_index is None and device_str.startswith('hw:'):
                        # Parse hw:x,y to get card and device numbers
                        try:
                            hw_parts = device_str.replace('hw:', '').split(',')
                            card_num = int(hw_parts[0])
                            
                            # Find PyAudio device index by searching for matching ALSA name
                            import pyaudio
                            p = pyaudio.PyAudio()
                            try:
                                for i in range(p.get_device_count()):
                                    info = p.get_device_info_by_index(i)
                                    name = info.get('name', '').lower()
                                    # Check if device name contains "hw:x,y" pattern
                                    if f"hw:{card_num}" in name.lower() or f"card{card_num}" in name.lower():
                                        if info.get('maxInputChannels', 0) > 0:
                                            self.audio_device_index = i
                                            print(f"   â†³ TÃ¬m tháº¥y PyAudio device index: {i} ({info['name']})")
                                            break
                            finally:
                                p.terminate()
                        except Exception as e:
                            print(f"âš ï¸ Lá»—i parse hw string: {e}")
                    
                    self.audio_dev = device_str  # Giá»¯ config cho log
                    
                    if self.audio_device_index is None:
                        print(f"âš ï¸ KhÃ´ng thá»ƒ tÃ¬m PyAudio device index tá»«: {device_str}")
                        self.audio_device_index = None
                    else:
                        # Kiá»ƒm tra device cÃ³ há»— trá»£ sample rate tá»« config khÃ´ng
                        p = pyaudio.PyAudio()
                        try:
                            device_info = p.get_device_info_by_index(self.audio_device_index)
                            print(f"   â†³ Device info: {device_info.get('name')}")
                            print(f"   â†³ Max input channels: {device_info.get('maxInputChannels')}")
                            print(f"   â†³ Default sample rate: {device_info.get('defaultSampleRate')}Hz")
                            
                            # Kiá»ƒm tra sá»‘ channels há»— trá»£
                            max_channels = int(device_info.get('maxInputChannels', 0))
                            if max_channels == 0:
                                print(f"âš ï¸ Device khÃ´ng há»— trá»£ input")
                                self.audio_device_index = None
                            else:
                                # Chá»n channels phÃ¹ há»£p
                                config_channels = self.config['audio'].get('channels', 1)
                                self.audio_channels = min(config_channels, max_channels)
                                
                                # Láº¥y default sample rate tá»« thiáº¿t bá»‹
                                default_rate = int(device_info.get('defaultSampleRate', 44100))
                                
                                # Thá»­ default rate trÆ°á»›c (thÆ°á»ng lÃ  rate device há»— trá»£ tá»‘t nháº¥t)
                                supported_rates = [default_rate, 44100, 48000, 16000, 22050, 32000, 8000, 11025]
                                # Loáº¡i bá» duplicate
                                supported_rates = list(dict.fromkeys(supported_rates))
                                
                                self.audio_rate = None
                                for rate in supported_rates:
                                    # Thá»­ vá»›i cáº£ mono vÃ  stereo
                                    for test_channels in [self.audio_channels, 1, 2]:
                                        if test_channels > max_channels:
                                            continue
                                        try:
                                            # Test vá»›i input stream
                                            test_stream = p.open(
                                                format=pyaudio.paInt16,
                                                channels=test_channels,
                                                rate=rate,
                                                input=True,
                                                input_device_index=self.audio_device_index,
                                                frames_per_buffer=1024,
                                                start=False
                                            )
                                            test_stream.close()
                                            self.audio_rate = rate
                                            self.audio_channels = test_channels
                                            print(f"   âœ… TÃ¬m tháº¥y cáº¥u hÃ¬nh phÃ¹ há»£p: {rate}Hz, {test_channels}ch")
                                            break
                                        except Exception as e:
                                            # Debug: in ra lá»—i cá»¥ thá»ƒ
                                            if "Invalid sample rate" in str(e):
                                                pass  # Rate khÃ´ng há»— trá»£, thá»­ rate khÃ¡c
                                            continue
                                    if self.audio_rate is not None:
                                        break
                                
                                if self.audio_rate is None:
                                    print(f"âš ï¸ KhÃ´ng tÃ¬m Ä‘Æ°á»£c sample rate phÃ¹ há»£p")
                                    print(f"   â†³ Thá»­ cÃ¡c rate: {supported_rates}")
                                    print(f"   â†³ Default rate cá»§a device: {default_rate}Hz")
                                    self.audio_device_index = None
                        except Exception as e:
                            print(f"âš ï¸ Lá»—i kiá»ƒm tra device: {e}")
                            self.audio_device_index = None
                        finally:
                            p.terminate()
                else:
                    self.audio_device_index = None
                    print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y thiáº¿t bá»‹ audio.")
                
                # Kiá»ƒm tra cuá»‘i cÃ¹ng
                if self.audio_device_index is not None and hasattr(self, 'audio_rate'):
                    print(f"   â†³ Audio config: {self.audio_channels}ch @ {self.audio_rate}Hz")
                else:
                    self.audio_device_index = None
                    print("   âœ–ï¸ Audio: KhÃ´ng thá»ƒ khá»Ÿi táº¡o")
            else:
                self.audio_device_index = None
            
            # Cáº¥u hÃ¬nh lÆ°u trá»¯
            self.output_dir = self.config['paths']['record_root']
            self.segment_seconds = self.config['storage']['segment_seconds']
            
            # Äáº£m báº£o thÆ° má»¥c tá»“n táº¡i
            os.makedirs(self.output_dir, exist_ok=True)
            os.makedirs(self.hls_dir, exist_ok=True)
            
            print("âœ… ÄÃ£ khá»Ÿi táº¡o cáº¥u hÃ¬nh:")
            print(f"   â†³ Video: index {self.video_index} ({self.video_size} @ {self.video_fps}fps)")
            if hasattr(self, 'audio_dev') and self.audio_device_index is not None:
                print(f"   â†³ Audio: {self.audio_dev} (index {self.audio_device_index}, {self.audio_channels}ch @ {self.audio_rate}Hz)")
            else:
                print("   âœ–ï¸ Audio: KhÃ´ng cÃ³ thiáº¿t bá»‹ audio")
            print(f"   â†³ Storage: {self.output_dir}")
            print(f"   â†³ Segment: {self.segment_seconds}s")
            
            # Setup Flask routes (always setup broadcast thread)
            self.setup_flask_routes()
            print("   âœ… Flask routes Ä‘Ã£ Ä‘Æ°á»£c thiáº¿t láº­p")
            return True
            
        except KeyError as e:
            print(f"âŒ Lá»—i cáº¥u hÃ¬nh: Thiáº¿u thÃ´ng sá»‘ {e}")
            return False
        except Exception as e:
            print(f"âŒ Lá»—i khá»Ÿi táº¡o: {e}")
            return False

    def _get_rtc_time(self):
        """Äá»c thá»i gian tá»« RTC module"""
        try:
            if self.rtc_available:
                rtc_time = self.rtc.read_time()
                return rtc_time.strftime("%Y-%m-%d %H:%M:%S")
            else:
                return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        except Exception as e:
            # print(f"âš ï¸ Lá»—i Ä‘á»c RTC: {e}")
            return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def _get_gps_info(self):
        """Äá»c thÃ´ng tin GPS tá»« GNSS module"""
        try:
            if self.gnss_available:
                gps_data = self.gnss.get_location()
                if gps_data and gps_data.get('fix_quality', 0) > 0:
                    lat = gps_data.get('latitude', 0)
                    lon = gps_data.get('longitude', 0)
                    speed = gps_data.get('speed', 0)
                    alt = gps_data.get('altitude', 0)
                    sats = gps_data.get('satellites', 0)
                    return f"GPS: {lat:.6f}, {lon:.6f} | Alt: {alt:.1f}m | Spd: {speed:.1f}km/h | Sats: {sats}"
                return "GPS: Chá» tÃ­n hiá»‡u"
            return None
        except Exception as e:
            print(f"âš ï¸ Lá»—i Ä‘á»c GPS: {e}")
            return None

    def _get_overlay_text(self):
        """Láº¥y text overlay (thay vÃ¬ file, dÃ¹ng direct cho OpenCV)"""
        timestamp = self._get_rtc_time()
        gps_info = self._get_gps_info() or "GPS: Waiting for signal"
        return f"{timestamp}\n{gps_info}"

    def setup_flask_routes(self):
        """Setup WebSocket handlers for video stream"""
        socketio = self.socketio  # Reference to SocketIO instance
        ws_clients = self.ws_clients  # Reference to clients set
        
        # Only register routes once
        if '/' not in [rule.rule for rule in self.app.url_map.iter_rules()]:
            @self.app.route('/')
            def index():
                return "Recorder service running (WebSocket + MJPEG enabled)"
            
            @self.app.route('/stream')
            def mjpeg_stream():
                """MJPEG stream endpoint (khÃ´ng cáº§n WebSocket)"""
                def gen_frames():
                    """Generator Ä‘á»ƒ stream MJPEG frames"""
                    while not self._stop_flag:
                        with self.frame_lock:
                            if not self.frame_queue:
                                time.sleep(0.05)
                                continue
                            frame = self.frame_queue[-1]
                        
                        # Encode frame as JPEG (lower quality = faster)
                        ret, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 60])
                        if ret:
                            frame_bytes = buffer.tobytes()
                            yield (b'--frame\r\n'
                                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
                        
                        time.sleep(1 / self.video_fps)  # Control FPS
                
                return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')
        
        @socketio.on('connect')
        def handle_connect():
            print(f"ğŸ‘¤ Client connected")
            # We can't easily get session_id here without request, just increment
        
        @socketio.on('disconnect')
        def handle_disconnect():
            print(f"ğŸ‘‹ Client disconnected")
            
        def broadcast_frame():
            """Broadcast video frame to all connected clients"""
            print("ğŸ¬ Broadcast thread started")
            frame_count = 0
            while not self._stop_flag:
                # Always broadcast if there are frames
                with self.frame_lock:
                    if not self.frame_queue:
                        time.sleep(0.05)
                        continue
                    frame = self.frame_queue[-1]
                    self.frame_queue = [frame]  # Keep only latest
                
                try:
                    # Encode frame as JPEG then base64 (lower quality = faster)
                    ret, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 60])
                    if ret:
                        b64_frame = base64.b64encode(buffer).decode('utf-8')
                        # Broadcast to all clients
                        socketio.emit('video_frame', {'frame': b64_frame})
                        frame_count += 1
                        if frame_count % 30 == 0:  # Log every 30 frames (2 seconds at 15fps)
                            print(f"ğŸ“¡ Broadcasted {frame_count} frames")
                except Exception as e:
                    print(f"âŒ Error broadcasting frame: {e}")
                
                time.sleep(1 / self.video_fps)  # Control FPS
                
        # Start broadcasting thread
        self.broadcast_thread = threading.Thread(target=broadcast_frame, daemon=True)
        self.broadcast_thread.start()

    def _mux_to_mp4(self):
        """GhÃ©p AVI + WAV thÃ nh MP4 báº±ng ffmpeg_merge_video_audio"""
        if not hasattr(self, 'segment_manager'):
            return
            
        paths = self.segment_manager.get_current_paths()
        video_file = paths['video']
        audio_file = paths['audio']
        mp4_file = paths['output']
        
        if not os.path.exists(video_file):
            print("âš ï¸ KhÃ´ng cÃ³ file video Ä‘á»ƒ ghÃ©p.")
            return

        try:
            # Sá»­ dá»¥ng ffmpeg_merge_video_audio Ä‘á»ƒ ghÃ©p
            if os.path.exists(audio_file):
                # GhÃ©p video vÃ  audio
                ffmpeg_merge_video_audio(
                    video_file,
                    audio_file,
                    mp4_file,
                    video_codec="libx264",
                    audio_codec="aac",
                )
                print(f"âœ… GhÃ©p thÃ nh cÃ´ng: {mp4_file} (video AVI + audio WAV)")
            else:
                # Chá»‰ convert video sang MP4 khÃ´ng cÃ³ audio
                ffmpeg_merge_video_audio(
                    video_file,
                    None,
                    mp4_file,
                    video_codec="libx264",
                    audio_codec="aac",
                )
                print(f"âœ… Convert thÃ nh cÃ´ng: {mp4_file} (video only)")
            
            # Cleanup source files sau khi ghÃ©p thÃ nh cÃ´ng
            try:
                if os.path.exists(video_file):
                    os.remove(video_file)
                    print(f"   â†³ ÄÃ£ xÃ³a file video: {video_file}")
                if os.path.exists(audio_file):
                    os.remove(audio_file)
                    print(f"   â†³ ÄÃ£ xÃ³a file audio: {audio_file}")
            except Exception as e:
                print(f"âš ï¸ Lá»—i xoÃ¡ file nguá»“n: {e}")
                print(f"   â†³ Video exists: {os.path.exists(video_file)}")
                print(f"   â†³ Audio exists: {os.path.exists(audio_file)}")
                
        except Exception as e:
            print(f"âš ï¸ Lá»—i ghÃ©p MP4: {e}")
            # Cleanup on error
            if os.path.exists(mp4_file):
                try:
                    os.remove(mp4_file)
                    print(f"   â†³ ÄÃ£ xÃ³a file MP4 lá»—i: {mp4_file}")
                except Exception as e:
                    print(f"âš ï¸ Lá»—i xÃ³a file MP4: {e}")

    def _audio_thread(self):
        """Thread Ä‘á»c vÃ  ghi audio Ä‘á»™c láº­p"""
        if self.audio_device_index is None:
            print("âš ï¸ KhÃ´ng cÃ³ thiáº¿t bá»‹ audio, audio thread khÃ´ng cháº¡y")
            return

        # Cáº¥u hÃ¬nh cá»‘ Ä‘á»‹nh Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh á»•n Ä‘á»‹nh
        CHUNK = 1024
        FORMAT = pyaudio.paInt16
        CHANNELS = 1
        RATE = 48000

        p = pyaudio.PyAudio()
        try:
            stream = p.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                frames_per_buffer=CHUNK,
                input=True,
                # input_device_index=self.audio_device_index
            )
            print(f"âœ… Khá»Ÿi táº¡o audio stream thÃ nh cÃ´ng ({RATE}Hz, {CHANNELS} channels)")
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ má»Ÿ audio stream: {e}")
            p.terminate()
            return

        # Äáº£m báº£o cÃ³ SegmentManager vÃ  segment Ä‘Ã£ Ä‘Æ°á»£c báº¯t Ä‘áº§u
        if not hasattr(self, 'segment_manager'):
            self.segment_manager = SegmentManager(self.output_dir, self.segment_seconds)
            
        # Äá»£i segment Ä‘Æ°á»£c khá»Ÿi táº¡o bá»Ÿi video thread
        wait_start = time.time()
        while self.segment_manager.current_segment is None:
            if time.time() - wait_start > 5:  # Timeout sau 5 giÃ¢y
                print("âš ï¸ Timeout chá» video thread khá»Ÿi táº¡o segment")
                return
            time.sleep(0.1)

        # Báº¯t Ä‘áº§u ghi audio vÃ o segment hiá»‡n táº¡i
        current_segment = self.segment_manager.get_current_paths()['audio']
        current_writer = wave.open(current_segment, 'wb')
        current_writer.setnchannels(CHANNELS)
        current_writer.setsampwidth(p.get_sample_size(FORMAT))  # 16-bit PCM
        current_writer.setframerate(RATE)
        audio_frames = []  # Initialize array to store frames

        while not self._stop_flag:
            try:
                data = stream.read(CHUNK)  # Äá»c chunk data tá»« stream
                audio_frames.append(data)
                
                # Kiá»ƒm tra segment má»›i
                if self.segment_manager.should_start_new():
                    # Ghi toÃ n bá»™ frames vÃ o file WAV
                    current_writer.writeframes(b''.join(audio_frames))
                    current_writer.close()
                    self.segment_manager.mark_complete('audio')
                    
                    # Äá»£i video hoÃ n thÃ nh vÃ  ghÃ©p file
                    if self.segment_manager.wait_for_merge(timeout=1.0):
                        self._mux_to_mp4()
                    
                    # Báº¯t Ä‘áº§u segment má»›i
                    current_segment = self.segment_manager.get_current_paths()['audio']
                    current_writer = wave.open(current_segment, 'wb')
                    current_writer.setnchannels(CHANNELS)
                    current_writer.setsampwidth(p.get_sample_size(FORMAT))
                    current_writer.setframerate(RATE)
                    audio_frames = []  # Reset frame buffer
                    
            except Exception as e:
                print(f"âš ï¸ Lá»—i Ä‘á»c audio: {e}")
                time.sleep(0.1)

        # Ghi ná»‘t pháº§n cuá»‘i
        if audio_frames:
            current_writer.writeframes(b''.join(audio_frames))
        current_writer.close()
        self.segment_manager.mark_complete('audio')
        
        # Cleanup
        stream.stop_stream()
        stream.close()
        p.terminate()
        print("âœ… Audio thread stopped.")

    def _video_thread(self):
        """Thread Ä‘á»c vÃ  ghi video Ä‘á»™c láº­p vá»›i auto-reconnect"""
        cap = None
        reconnect_attempts = 0
        max_reconnect = 5
        
        def init_camera():
            """Khá»Ÿi táº¡o hoáº·c khá»Ÿi táº¡o láº¡i camera - Ä‘Æ¡n giáº£n nhÆ° Flask example"""
            new_cap = cv2.VideoCapture(self.video_index)
            if new_cap.isOpened():
                # Chá»‰ set resolution, khÃ´ng set buffer hay FPS phá»©c táº¡p
                new_cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.video_width)
                new_cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.video_height)
                return new_cap
            return None
        
        # Khá»Ÿi táº¡o camera láº§n Ä‘áº§u
        cap = init_camera()
        self.cap = cap  # LÆ°u reference Ä‘á»ƒ cleanup sau
        
        if cap is None:
            print("âŒ KhÃ´ng má»Ÿ Ä‘Æ°á»£c camera!")
            return
        
        # Khá»Ÿi táº¡o SegmentManager náº¿u chÆ°a cÃ³
        if not hasattr(self, 'segment_manager'):
            self.segment_manager = SegmentManager(self.output_dir, self.segment_seconds)
            
        # Báº¯t Ä‘áº§u segment Ä‘áº§u tiÃªn
        current_segment = self.segment_manager.start_new_segment()
        current_writer = cv2.VideoWriter(
            f"{current_segment}.avi",
            cv2.VideoWriter_fourcc(*'XVID'),
            self.video_fps,
            (self.video_width, self.video_height)
        )

        while not self._stop_flag:
            ret, frame = cap.read()
            if not ret:
                print("âš ï¸ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c frame, thá»­ reconnect...")
                
                # ÄÃ³ng camera hiá»‡n táº¡i
                try:
                    cap.release()
                    time.sleep(1)  # Äá»£i driver reset
                except:
                    pass
                
                # Thá»­ reconnect
                reconnect_attempts += 1
                if reconnect_attempts > max_reconnect:
                    print(f"âŒ ÄÃ£ thá»­ reconnect {max_reconnect} láº§n tháº¥t báº¡i, dá»«ng video thread")
                    break
                
                print(f"ğŸ”„ Äang reconnect camera... (láº§n {reconnect_attempts}/{max_reconnect})")
                cap = init_camera()
                self.cap = cap
                
                if cap is None:
                    print("âŒ Reconnect tháº¥t báº¡i, thá»­ láº¡i sau 2 giÃ¢y...")
                    time.sleep(2)
                    continue
                else:
                    print("âœ… Reconnect camera thÃ nh cÃ´ng!")
                    reconnect_attempts = 0  # Reset counter khi thÃ nh cÃ´ng
                    continue

            # Reset reconnect counter khi Ä‘á»c frame thÃ nh cÃ´ng
            reconnect_attempts = 0

            # Add overlay text direct (chá»‰ má»—i 2 giÃ¢y thay vÃ¬ má»—i frame)
            current_time = time.time()
            if not hasattr(self, '_last_overlay_update'):
                self._last_overlay_update = 0
            
            if current_time - self._last_overlay_update >= 1.0:
                self._overlay_text_cached = self._get_overlay_text()
                self._last_overlay_update = current_time
            
            # DÃ¹ng cached text
            if hasattr(self, '_overlay_text_cached'):
                overlay_text = self._overlay_text_cached
                lines = overlay_text.split('\n')
                y_offset = 10
                for line in lines:
                    cv2.putText(frame, line, (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    y_offset += 25

            # Write video frame
            current_writer.write(frame)

            # Push frame for MJPEG stream (chá»‰ giá»¯ frame má»›i nháº¥t)
            with self.frame_lock:
                self.frame_queue = [frame]  # Overwrite thay vÃ¬ append

            # Check if need new segment
            if self.segment_manager.should_start_new():
                current_writer.release()
                self.segment_manager.mark_complete('video')
                
                # Äá»£i audio hoÃ n thÃ nh vÃ  báº¯t Ä‘áº§u segment má»›i
                if self.segment_manager.wait_for_merge(timeout=1.0):
                    self._mux_to_mp4()
                    
                current_segment = self.segment_manager.start_new_segment()
                current_writer = cv2.VideoWriter(
                    f"{current_segment}.avi",
                    cv2.VideoWriter_fourcc(*'XVID'),
                    self.video_fps,
                    (self.video_width, self.video_height)
                )

            time.sleep(1 / self.video_fps)  # Control FPS

        # Final segment
        current_writer.release()
        self.segment_manager.mark_complete('video')
        if self.segment_manager.wait_for_merge(timeout=1.0):
            self._mux_to_mp4()
        cap.release()
        print("âœ… Video thread stopped.")

    def start(self):
        # Check if threads already running
        if hasattr(self, '_video_thread_obj') and self._video_thread_obj and self._video_thread_obj.is_alive():
            print("âš ï¸ Video thread Ä‘ang cháº¡y!")
            return
        if hasattr(self, '_audio_thread_obj') and self._audio_thread_obj and self._audio_thread_obj.is_alive():
            print("âš ï¸ Audio thread Ä‘ang cháº¡y!")
            return

        # Kiá»ƒm tra láº¡i storage trÆ°á»›c khi báº¯t Ä‘áº§u ghi
        if hasattr(self, 'usb_manager'):
            if not self.usb_manager.is_available():
                print("âš ï¸ USB storage khÃ´ng kháº£ dá»¥ng!")
                # Nháº¥p nhÃ¡y LED khi USB khÃ´ng kháº£ dá»¥ng
                self.led_control.blink(0.5)  # Nháº¥p nhÃ¡y vá»›i táº§n sá»‘ 0.5 giÃ¢y
                return
            if not self.usb_manager.has_enough_space():
                print("âš ï¸ KhÃ´ng Ä‘á»§ dung lÆ°á»£ng trá»‘ng!")
                return

        self._stop_flag = False
        print(f"ğŸš€ Báº¯t Ä‘áº§u ghi vÃ  stream (má»—i {self.segment_seconds}s lÆ°u 1 file MP4 ghÃ©p video+audio)...")
        print("   â†³ LÆ°u táº¡i:", self.output_dir)
        
        # Initialize segment manager before starting threads
        self.segment_manager = SegmentManager(self.output_dir, self.segment_seconds)
        
        # Start video thread first
        self._video_thread_obj = threading.Thread(target=self._video_thread, daemon=True)
        self._video_thread_obj.start()
        
        # Wait for video thread to initialize
        start_time = time.time()
        while self.segment_manager.current_segment is None:
            if time.time() - start_time > 5:
                print("âš ï¸ Timeout chá» video thread khá»Ÿi táº¡o")
                return
            time.sleep(0.1)
            
        print("âœ… Video thread Ä‘Ã£ khá»Ÿi Ä‘á»™ng")

        # Start audio thread if device available
        if self.audio_device_index is not None:
            self._audio_thread_obj = threading.Thread(target=self._audio_thread, daemon=True)
            self._audio_thread_obj.start()
            print("âœ… Audio thread Ä‘Ã£ khá»Ÿi Ä‘á»™ng")

        time.sleep(2)  # Äá»£i setup

        if self._video_thread_obj.is_alive():
            print("âœ… Video thread Ä‘Ã£ khá»Ÿi Ä‘á»™ng.")
            if hasattr(self, '_audio_thread_obj') and self._audio_thread_obj.is_alive():
                print("âœ… Audio thread Ä‘Ã£ khá»Ÿi Ä‘á»™ng.")
            # Báº­t LED khi báº¯t Ä‘áº§u ghi
            self.led_control.on()
        else:
            print("âŒ Video thread khÃ´ng khá»Ÿi Ä‘á»™ng Ä‘Æ°á»£c.")

    def _led_blink(self):
        """HÃ m Ä‘iá»u khiá»ƒn LED nháº¥p nhÃ¡y"""
        while self.led_running:
            self.led_control.on()
            time.sleep(0.5)
            self.led_control.off()
            time.sleep(0.5)

    def _start_led_blink(self):
        """Báº¯t Ä‘áº§u nháº¥p nhÃ¡y LED trong thread riÃªng"""
        self.led_running = True
        self.led_thread = threading.Thread(target=self._led_blink)
        self.led_thread.daemon = True
        self.led_thread.start()

    def _stop_led_blink(self):
        """Dá»«ng nháº¥p nhÃ¡y LED"""
        self.led_running = False
        if self.led_thread:
            self.led_thread.join(timeout=1)
        self.led_control.off()

    def stop(self):
        self._stop_flag = True
        # Dá»«ng video thread
        if hasattr(self, '_video_thread_obj') and self._video_thread_obj:
            print("â± Dá»«ng video thread...")
            self._video_thread_obj.join(timeout=5)
            if self._video_thread_obj.is_alive():
                print("âš ï¸ Video thread váº«n Ä‘ang cháº¡y sau 5 giÃ¢y timeout.")
                
        # Dá»«ng audio thread
        if hasattr(self, '_audio_thread_obj') and self._audio_thread_obj:
            print("â± Dá»«ng audio thread...")
            self._audio_thread_obj.join(timeout=5)
            if self._audio_thread_obj.is_alive():
                print("âš ï¸ Audio thread váº«n Ä‘ang cháº¡y sau 5 giÃ¢y timeout.")
                
        # Táº¯t LED khi dá»«ng ghi
        self.led_control.off()
        print("âœ… ÄÃ£ dá»«ng cÃ¡c thread.")

    def cleanup(self):
        """
        Dá»«ng an toÃ n threads, FFmpeg, cÃ¡c module pháº§n cá»©ng (LED, GNSS, RTC),
        trÃ¡nh crash camera trÃªn Raspberry Pi.
        """
        print("ğŸ§¹ Báº¯t Ä‘áº§u cleanup...")

        # 1ï¸âƒ£ Set stop flag Ä‘á»ƒ threads tá»± dá»«ng
        self._stop_flag = True

        # 2ï¸âƒ£ Dá»«ng video/audio/mux threads
        self.stop()
        
        # 2.5ï¸âƒ£ Force release camera náº¿u cÃ²n tá»“n Ä‘á»ng
        if hasattr(self, 'cap') and self.cap is not None:
            try:
                if self.cap.isOpened():
                    self.cap.release()
                    print("ğŸ“¹ Camera Ä‘Ã£ Ä‘Æ°á»£c release")
                    time.sleep(0.5)  # Äá»£i driver reset
            except Exception as e:
                print(f"âš ï¸ Lá»—i release camera: {e}")
        
        # Force giáº£i phÃ³ng tÃ i nguyÃªn OpenCV
        try:
            cv2.destroyAllWindows()
        except:
            pass

        # 3ï¸âƒ£ Táº¯t LED (náº¿u cÃ³)
        if hasattr(self, 'led_control'):
            try:
                self.led_control.off()
                print("ğŸ’¡ LED Ä‘Ã£ táº¯t")
            except Exception as e:
                print(f"âš ï¸ Lá»—i khi táº¯t LED: {e}")

        # 4ï¸âƒ£ ÄÃ³ng GNSS module (náº¿u cÃ³)
        if hasattr(self, 'gnss') and getattr(self, 'gnss_available', False):
            try:
                self.gnss.close()
                print("ğŸ“¡ GNSS module Ä‘Ã£ Ä‘Ã³ng")
            except Exception as e:
                print(f"âš ï¸ Lá»—i khi Ä‘Ã³ng GNSS: {e}")

        # 5ï¸âƒ£ ÄÃ³ng RTC module (náº¿u cÃ³)
        if hasattr(self, 'rtc') and getattr(self, 'rtc_available', False):
            try:
                self.rtc.close()
                print("â° RTC module Ä‘Ã£ Ä‘Ã³ng")
            except Exception as e:
                print(f"âš ï¸ Lá»—i khi Ä‘Ã³ng RTC: {e}")

        print("âœ… Cleanup hoÃ n táº¥t, táº¥t cáº£ module Ä‘Ã£ dá»«ng an toÃ n.")


def signal_handler(signum, frame):
    """Xá»­ lÃ½ tÃ­n hiá»‡u Ä‘á»ƒ thoÃ¡t an toÃ n"""
    print("\nğŸ›‘ Nháº­n tÃ­n hiá»‡u dá»«ng, Ä‘ang thoÃ¡t...")
    if 'recorder' in globals():
        recorder.cleanup()
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        recorder = PiStreamer()
        if not recorder.initial():
            print("âŒ Khá»Ÿi táº¡o tháº¥t báº¡i, Ä‘ang thoÃ¡t...")
            sys.exit(1)

        recorder.start()  # ğŸ”¹ Start recorder threads
        print("ğŸ“¡ Äang stream... WebSocket server táº¡i ws://localhost:5000")
        
        # Run SocketIO app
        recorder.socketio.run(recorder.app, host="0.0.0.0", port=5000, allow_unsafe_werkzeug=True)

    except KeyboardInterrupt:
        print("\nğŸ›‘ Äang thoÃ¡t...")
        recorder.cleanup()
    except Exception as e:
        print(f"âŒ Lá»—i chÆ°Æ¡ng trÃ¬nh: {e}")
        sys.exit(1)